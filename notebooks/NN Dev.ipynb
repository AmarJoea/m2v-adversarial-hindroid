{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "import os\n",
    "os.chdir('/home/rcgonzal/DSC180Malware/m2v-adversarial-hindroid/')\n",
    "\n",
    "from __future__ import print_function\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from src.imbalanced_dataset_sampler.imbalanced import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "covered-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HindroidDataset(Dataset):\n",
    "    def __init__(self, features_path, labels_path, label_col='m2vDroid', transform=None):\n",
    "        '''\n",
    "        Creates a  dataset from the A matrix representation of apps and their associated labels.\n",
    "        \n",
    "        Parameters:\n",
    "        -------------------\n",
    "        features_path: Path to A matrix in sparse format.\n",
    "        labels_path: Path to labels in csv format.\n",
    "        label_col: Default 'm2vDroid'. Useful for specifying which kernel to use for HinDroid.\n",
    "        '''\n",
    "        self.features = sparse.load_npz(os.path.join(features_path))\n",
    "        self.feature_width = self.features.shape[1]\n",
    "        features_folder = os.path.split(features_path)[0]\n",
    "        self.features_idx = list(pd.read_csv(\n",
    "            os.path.join(features_folder, 'predictions.csv'),\n",
    "            usecols=['app'], \n",
    "            squeeze=True\n",
    "        ))\n",
    "        self.transform = transform\n",
    "        \n",
    "        try:\n",
    "            self.labels = pd.read_csv(\n",
    "                labels_path, \n",
    "                usecols=['app', label_col],\n",
    "                index_col = 'app',\n",
    "                squeeze=True\n",
    "            )\n",
    "            self.labels = self.labels[self.features_idx].values # align labels with features index\n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(e)\n",
    "            print('Seems like you may be trying to use a different model. This class is setup for m2vDroid by default.')\n",
    "            print('For HinDroid you must specify `label_col` as either AAT, ABAT, APAT, ABPBTAT, or APBPTAT.')\n",
    "            \n",
    "        assert (self.features.shape[0] == self.labels.size), 'Length mismatch between features and labels.'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        features = self.features[idx]\n",
    "        features = features.todense().astype('float').A\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "#         if self.transform:\n",
    "#             features = self.transform(features)\n",
    "#             labels = self.transform(labels)\n",
    "        \n",
    "#         sample = {'features': features, 'labels': labels}\n",
    "        \n",
    "        return features, labels\n",
    "    \n",
    "    def get_labels(self, idx):\n",
    "        return self.labels[idx]\n",
    "    \n",
    "def hindroid_custom_get_label(dataset, idx):\n",
    "    return dataset.get_labels(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "universal-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HindroidSubstitute(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(HindroidSubstitute, self).__init__()\n",
    "        self.layer_1 = nn.Linear(n_features, 64, bias=False)\n",
    "        # Linear - how to freeze layer ^\n",
    "        # biases = false\n",
    "        self.layer_2 = nn.Linear(64, 64, bias=False)\n",
    "        self.layer_3 = nn.Linear(64, 64, bias=False)\n",
    "        self.layer_4 = nn.Linear(64, 2, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.from_numpy(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.relu(self.layer_2(x))\n",
    "        x = F.relu(self.layer_3(x))\n",
    "        x = self.layer_4(x)\n",
    "        return x # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "periodic-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "# model = HindroidSubstitute(dataset.feature_width).double()\n",
    "# model(dataset[-100:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statistical-review",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The negative log likelihood loss.\n",
       "\n",
       "See :class:`~torch.nn.NLLLoss` for details.\n",
       "\n",
       "Args:\n",
       "    input: :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n",
       "        in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \\geq 1`\n",
       "        in the case of K-dimensional loss.\n",
       "    target: :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`,\n",
       "        or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \\geq 1` for\n",
       "        K-dimensional loss.\n",
       "    weight (Tensor, optional): a manual rescaling weight given to each\n",
       "        class. If given, has to be a Tensor of size `C`\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when reduce is ``False``. Default: ``True``\n",
       "    ignore_index (int, optional): Specifies a target value that is ignored\n",
       "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
       "        ``True``, the loss is averaged over non-ignored targets. Default: -100\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
       "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
       "        ``'mean'``: the sum of the output will be divided by the number of\n",
       "        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
       "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
       "        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> # input is of size N x C = 3 x 5\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> # each element in target has to have 0 <= value < C\n",
       "    >>> target = torch.tensor([1, 0, 4])\n",
       "    >>> output = F.nll_loss(F.log_softmax(input), target)\n",
       "    >>> output.backward()\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.8/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F.nll_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decreased-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, weight=None):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(model(data), dim=1)\n",
    "        loss = F.nll_loss(output, target, weight=weight) # do we use different loss?\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # logging\n",
    "        log_interval = 10\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "#         if batch_idx % args.log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "#             if args.dry_run:\n",
    "#                 break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, weight=None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "#             print(output)\n",
    "            output = F.log_softmax(output, dim=1)\n",
    "#             print(output)\n",
    "            loss = F.nll_loss(output, target, weight=weight, reduction='sum').item()  # sum up batch loss\n",
    "#             print('loss: ', loss)\n",
    "            test_loss += loss\n",
    "#             print(output.argmax(dim=1, keepdim=True))\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#             print(target.view_as(pred))\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HindroidSubstitute(dataset.feature_width).double()\n",
    "# weights = torch.Tensor([dataset.labels.mean() / (1-dataset.labels.mean()), 1]).double()\n",
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=10)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset, batch_size=10)\n",
    "# test(model, 'cpu', test_loader, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-beginning",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dutch-monroe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6072 (0%)]\tLoss: 0.693231\n",
      "Train Epoch: 1 [1000/6072 (16%)]\tLoss: 0.617559\n",
      "Train Epoch: 1 [2000/6072 (33%)]\tLoss: 0.532660\n",
      "Train Epoch: 1 [3000/6072 (49%)]\tLoss: 0.478942\n",
      "Train Epoch: 1 [4000/6072 (66%)]\tLoss: 0.463148\n",
      "Train Epoch: 1 [5000/6072 (82%)]\tLoss: 0.376212\n",
      "Train Epoch: 1 [4320/6072 (98%)]\tLoss: 0.392915\n",
      "\n",
      "Test set: Average loss: 0.3780, Accuracy: 5958/6072 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/6072 (0%)]\tLoss: 0.361646\n",
      "Train Epoch: 2 [1000/6072 (16%)]\tLoss: 0.421938\n",
      "Train Epoch: 2 [2000/6072 (33%)]\tLoss: 0.369513\n",
      "Train Epoch: 2 [3000/6072 (49%)]\tLoss: 0.353823\n",
      "Train Epoch: 2 [4000/6072 (66%)]\tLoss: 0.405219\n",
      "Train Epoch: 2 [5000/6072 (82%)]\tLoss: 0.356002\n",
      "Train Epoch: 2 [4320/6072 (98%)]\tLoss: 0.418562\n",
      "\n",
      "Test set: Average loss: 0.3674, Accuracy: 5964/6072 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/6072 (0%)]\tLoss: 0.374777\n",
      "Train Epoch: 3 [1000/6072 (16%)]\tLoss: 0.346728\n",
      "Train Epoch: 3 [2000/6072 (33%)]\tLoss: 0.359628\n",
      "Train Epoch: 3 [3000/6072 (49%)]\tLoss: 0.386685\n",
      "Train Epoch: 3 [4000/6072 (66%)]\tLoss: 0.313852\n",
      "Train Epoch: 3 [5000/6072 (82%)]\tLoss: 0.388947\n",
      "Train Epoch: 3 [4320/6072 (98%)]\tLoss: 0.358845\n",
      "\n",
      "Test set: Average loss: 0.3674, Accuracy: 5966/6072 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/6072 (0%)]\tLoss: 0.361769\n",
      "Train Epoch: 4 [1000/6072 (16%)]\tLoss: 0.375139\n",
      "Train Epoch: 4 [2000/6072 (33%)]\tLoss: 0.355607\n",
      "Train Epoch: 4 [3000/6072 (49%)]\tLoss: 0.399761\n",
      "Train Epoch: 4 [4000/6072 (66%)]\tLoss: 0.391224\n",
      "Train Epoch: 4 [5000/6072 (82%)]\tLoss: 0.347331\n",
      "Train Epoch: 4 [4320/6072 (98%)]\tLoss: 0.335396\n",
      "\n",
      "Test set: Average loss: 0.3682, Accuracy: 5957/6072 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/6072 (0%)]\tLoss: 0.377227\n",
      "Train Epoch: 5 [1000/6072 (16%)]\tLoss: 0.380388\n",
      "Train Epoch: 5 [2000/6072 (33%)]\tLoss: 0.331079\n",
      "Train Epoch: 5 [3000/6072 (49%)]\tLoss: 0.354032\n",
      "Train Epoch: 5 [4000/6072 (66%)]\tLoss: 0.381412\n",
      "Train Epoch: 5 [5000/6072 (82%)]\tLoss: 0.360023\n",
      "Train Epoch: 5 [4320/6072 (98%)]\tLoss: 0.331616\n",
      "\n",
      "Test set: Average loss: 0.3714, Accuracy: 5938/6072 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/6072 (0%)]\tLoss: 0.361349\n",
      "Train Epoch: 6 [1000/6072 (16%)]\tLoss: 0.394463\n",
      "Train Epoch: 6 [2000/6072 (33%)]\tLoss: 0.353141\n",
      "Train Epoch: 6 [3000/6072 (49%)]\tLoss: 0.368487\n",
      "Train Epoch: 6 [4000/6072 (66%)]\tLoss: 0.416350\n",
      "Train Epoch: 6 [5000/6072 (82%)]\tLoss: 0.332673\n",
      "Train Epoch: 6 [4320/6072 (98%)]\tLoss: 0.426317\n",
      "\n",
      "Test set: Average loss: 0.3645, Accuracy: 5948/6072 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/6072 (0%)]\tLoss: 0.313013\n",
      "Train Epoch: 7 [1000/6072 (16%)]\tLoss: 0.393643\n",
      "Train Epoch: 7 [2000/6072 (33%)]\tLoss: 0.340542\n",
      "Train Epoch: 7 [3000/6072 (49%)]\tLoss: 0.345358\n",
      "Train Epoch: 7 [4000/6072 (66%)]\tLoss: 0.387287\n",
      "Train Epoch: 7 [5000/6072 (82%)]\tLoss: 0.368507\n",
      "Train Epoch: 7 [4320/6072 (98%)]\tLoss: 0.376596\n",
      "\n",
      "Test set: Average loss: 0.3688, Accuracy: 5974/6072 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/6072 (0%)]\tLoss: 0.342121\n",
      "Train Epoch: 8 [1000/6072 (16%)]\tLoss: 0.344060\n",
      "Train Epoch: 8 [2000/6072 (33%)]\tLoss: 0.328919\n",
      "Train Epoch: 8 [3000/6072 (49%)]\tLoss: 0.375085\n",
      "Train Epoch: 8 [4000/6072 (66%)]\tLoss: 0.383527\n",
      "Train Epoch: 8 [5000/6072 (82%)]\tLoss: 0.365745\n",
      "Train Epoch: 8 [4320/6072 (98%)]\tLoss: 0.366307\n",
      "\n",
      "Test set: Average loss: 0.3717, Accuracy: 5953/6072 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/6072 (0%)]\tLoss: 0.363047\n",
      "Train Epoch: 9 [1000/6072 (16%)]\tLoss: 0.334530\n",
      "Train Epoch: 9 [2000/6072 (33%)]\tLoss: 0.365580\n",
      "Train Epoch: 9 [3000/6072 (49%)]\tLoss: 0.332538\n",
      "Train Epoch: 9 [4000/6072 (66%)]\tLoss: 0.381836\n",
      "Train Epoch: 9 [5000/6072 (82%)]\tLoss: 0.392389\n",
      "Train Epoch: 9 [4320/6072 (98%)]\tLoss: 0.341349\n",
      "\n",
      "Test set: Average loss: 0.3723, Accuracy: 5951/6072 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/6072 (0%)]\tLoss: 0.347534\n",
      "Train Epoch: 10 [1000/6072 (16%)]\tLoss: 0.367174\n",
      "Train Epoch: 10 [2000/6072 (33%)]\tLoss: 0.394998\n",
      "Train Epoch: 10 [3000/6072 (49%)]\tLoss: 0.356781\n",
      "Train Epoch: 10 [4000/6072 (66%)]\tLoss: 0.337121\n",
      "Train Epoch: 10 [5000/6072 (82%)]\tLoss: 0.337685\n",
      "Train Epoch: 10 [4320/6072 (98%)]\tLoss: 0.367789\n",
      "\n",
      "Test set: Average loss: 0.3666, Accuracy: 5959/6072 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/6072 (0%)]\tLoss: 0.333820\n",
      "Train Epoch: 11 [1000/6072 (16%)]\tLoss: 0.382236\n",
      "Train Epoch: 11 [2000/6072 (33%)]\tLoss: 0.364627\n",
      "Train Epoch: 11 [3000/6072 (49%)]\tLoss: 0.374869\n",
      "Train Epoch: 11 [4000/6072 (66%)]\tLoss: 0.352948\n",
      "Train Epoch: 11 [5000/6072 (82%)]\tLoss: 0.351910\n",
      "Train Epoch: 11 [4320/6072 (98%)]\tLoss: 0.367117\n",
      "\n",
      "Test set: Average loss: 0.3716, Accuracy: 5951/6072 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/6072 (0%)]\tLoss: 0.360056\n",
      "Train Epoch: 12 [1000/6072 (16%)]\tLoss: 0.343030\n",
      "Train Epoch: 12 [2000/6072 (33%)]\tLoss: 0.375280\n",
      "Train Epoch: 12 [3000/6072 (49%)]\tLoss: 0.377144\n",
      "Train Epoch: 12 [4000/6072 (66%)]\tLoss: 0.391632\n",
      "Train Epoch: 12 [5000/6072 (82%)]\tLoss: 0.353673\n",
      "Train Epoch: 12 [4320/6072 (98%)]\tLoss: 0.298233\n",
      "\n",
      "Test set: Average loss: 0.3707, Accuracy: 5956/6072 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/6072 (0%)]\tLoss: 0.403974\n",
      "Train Epoch: 13 [1000/6072 (16%)]\tLoss: 0.381365\n",
      "Train Epoch: 13 [2000/6072 (33%)]\tLoss: 0.423743\n",
      "Train Epoch: 13 [3000/6072 (49%)]\tLoss: 0.388526\n",
      "Train Epoch: 13 [4000/6072 (66%)]\tLoss: 0.320531\n",
      "Train Epoch: 13 [5000/6072 (82%)]\tLoss: 0.370521\n",
      "Train Epoch: 13 [4320/6072 (98%)]\tLoss: 0.388871\n",
      "\n",
      "Test set: Average loss: 0.3665, Accuracy: 5965/6072 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/6072 (0%)]\tLoss: 0.381228\n",
      "Train Epoch: 14 [1000/6072 (16%)]\tLoss: 0.372460\n",
      "Train Epoch: 14 [2000/6072 (33%)]\tLoss: 0.294820\n",
      "Train Epoch: 14 [3000/6072 (49%)]\tLoss: 0.359944\n",
      "Train Epoch: 14 [4000/6072 (66%)]\tLoss: 0.367399\n",
      "Train Epoch: 14 [5000/6072 (82%)]\tLoss: 0.365528\n",
      "Train Epoch: 14 [4320/6072 (98%)]\tLoss: 0.371883\n",
      "\n",
      "Test set: Average loss: 0.3711, Accuracy: 5959/6072 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/6072 (0%)]\tLoss: 0.348164\n",
      "Train Epoch: 15 [1000/6072 (16%)]\tLoss: 0.343322\n",
      "Train Epoch: 15 [2000/6072 (33%)]\tLoss: 0.333091\n",
      "Train Epoch: 15 [3000/6072 (49%)]\tLoss: 0.356857\n",
      "Train Epoch: 15 [4000/6072 (66%)]\tLoss: 0.362174\n",
      "Train Epoch: 15 [5000/6072 (82%)]\tLoss: 0.374187\n",
      "Train Epoch: 15 [4320/6072 (98%)]\tLoss: 0.400941\n",
      "\n",
      "Test set: Average loss: 0.3686, Accuracy: 5933/6072 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/6072 (0%)]\tLoss: 0.378568\n",
      "Train Epoch: 16 [1000/6072 (16%)]\tLoss: 0.397607\n",
      "Train Epoch: 16 [2000/6072 (33%)]\tLoss: 0.368153\n",
      "Train Epoch: 16 [3000/6072 (49%)]\tLoss: 0.348278\n",
      "Train Epoch: 16 [4000/6072 (66%)]\tLoss: 0.366689\n",
      "Train Epoch: 16 [5000/6072 (82%)]\tLoss: 0.358508\n",
      "Train Epoch: 16 [4320/6072 (98%)]\tLoss: 0.359943\n",
      "\n",
      "Test set: Average loss: 0.3675, Accuracy: 5951/6072 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/6072 (0%)]\tLoss: 0.364915\n",
      "Train Epoch: 17 [1000/6072 (16%)]\tLoss: 0.347937\n",
      "Train Epoch: 17 [2000/6072 (33%)]\tLoss: 0.376756\n",
      "Train Epoch: 17 [3000/6072 (49%)]\tLoss: 0.369104\n",
      "Train Epoch: 17 [4000/6072 (66%)]\tLoss: 0.357214\n",
      "Train Epoch: 17 [5000/6072 (82%)]\tLoss: 0.376263\n",
      "Train Epoch: 17 [4320/6072 (98%)]\tLoss: 0.354149\n",
      "\n",
      "Test set: Average loss: 0.3690, Accuracy: 5951/6072 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/6072 (0%)]\tLoss: 0.379920\n",
      "Train Epoch: 18 [1000/6072 (16%)]\tLoss: 0.326264\n",
      "Train Epoch: 18 [2000/6072 (33%)]\tLoss: 0.382588\n",
      "Train Epoch: 18 [3000/6072 (49%)]\tLoss: 0.367484\n",
      "Train Epoch: 18 [4000/6072 (66%)]\tLoss: 0.362469\n",
      "Train Epoch: 18 [5000/6072 (82%)]\tLoss: 0.374253\n",
      "Train Epoch: 18 [4320/6072 (98%)]\tLoss: 0.360540\n",
      "\n",
      "Test set: Average loss: 0.3649, Accuracy: 5951/6072 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/6072 (0%)]\tLoss: 0.349852\n",
      "Train Epoch: 19 [1000/6072 (16%)]\tLoss: 0.373372\n",
      "Train Epoch: 19 [2000/6072 (33%)]\tLoss: 0.330367\n",
      "Train Epoch: 19 [3000/6072 (49%)]\tLoss: 0.350291\n",
      "Train Epoch: 19 [4000/6072 (66%)]\tLoss: 0.358882\n",
      "Train Epoch: 19 [5000/6072 (82%)]\tLoss: 0.395160\n",
      "Train Epoch: 19 [4320/6072 (98%)]\tLoss: 0.387541\n",
      "\n",
      "Test set: Average loss: 0.3716, Accuracy: 5943/6072 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/6072 (0%)]\tLoss: 0.345055\n",
      "Train Epoch: 20 [1000/6072 (16%)]\tLoss: 0.372180\n",
      "Train Epoch: 20 [2000/6072 (33%)]\tLoss: 0.349688\n",
      "Train Epoch: 20 [3000/6072 (49%)]\tLoss: 0.359736\n",
      "Train Epoch: 20 [4000/6072 (66%)]\tLoss: 0.385401\n",
      "Train Epoch: 20 [5000/6072 (82%)]\tLoss: 0.342440\n",
      "Train Epoch: 20 [4320/6072 (98%)]\tLoss: 0.375711\n",
      "\n",
      "Test set: Average loss: 0.3621, Accuracy: 5964/6072 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# train_kwargs = {'batch_size': args.batch_size}\n",
    "# test_kwargs = {'batch_size': args.test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "#                    'shuffle': True,\n",
    "                   'pin_memory': True}\n",
    "#     train_kwargs.update(cuda_kwargs)\n",
    "#     test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "# load data (will need to be adapted as well)\n",
    "# 1) load A_test\n",
    "# 2) load labels\n",
    "# 3) Perform train-test-split\n",
    "dataset = HindroidDataset(\n",
    "    'data/out/all-apps/hindroid-train-half/A_test.npz', \n",
    "    'data/out/all-apps/hindroid-train-half/predictions.csv',\n",
    "    'AAT',\n",
    ")\n",
    "# weights = torch.Tensor([dataset.labels.mean() / (1-dataset.labels.mean()), 1]).to(device).double()\n",
    "weights = None\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=100,\n",
    "    shuffle = False,\n",
    "    sampler = ImbalancedDatasetSampler(dataset, callback_get_label = hindroid_custom_get_label),\n",
    "    **cuda_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=100,\n",
    "    shuffle = False,\n",
    "    sampler = ImbalancedDatasetSampler(dataset, callback_get_label = hindroid_custom_get_label),\n",
    "    **cuda_kwargs)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=10)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset, batch_size=10)\n",
    "\n",
    "model = HindroidSubstitute(dataset.feature_width).double().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "for epoch in range(1, 20 + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, weights)\n",
    "    test(model, device, test_loader, weights)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "relevant-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90       481\n",
      "           1       1.00      0.98      0.99      5591\n",
      "\n",
      "    accuracy                           0.98      6072\n",
      "   macro avg       0.91      0.98      0.94      6072\n",
      "weighted avg       0.98      0.98      0.98      6072\n",
      "\n",
      "[[ 470   11]\n",
      " [  96 5495]]\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=100,\n",
    "    **cuda_kwargs)\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        all_preds.extend(pred.tolist())\n",
    "\n",
    "print(classification_report(dataset.labels, all_preds))\n",
    "print(confusion_matrix(dataset.labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "operational-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out/all-apps/hindroid-train-half/NN_sub.pkl', 'wb') as file:\n",
    "    torch.save(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "professional-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attack.cw import to_tanh_space, from_tanh_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "juvenile-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWZ0lEQVR4nO3de3BcZ3nH8d+jy2pXl5VkXSzfFF8Sx04IzkW50RIgSQsJU9JQoGm4dGiHwBQ67XTaUmCmMNNhhnagLbSU4NKUkmnJhEtIgJSUpBNoSU0ig5PYDgm+xPeLLMmSdVutpLd/7K68Z7Wy116dXe2r72dmZ7V7js5539j55cmz755jzjkBAPxUVe4BAADCQ8gDgMcIeQDwGCEPAB4j5AHAYzXlHkC29vZ2t3bt2nIPAwAqyvbt20855zrybVtUIb927Vr19vaWexgAUFHM7MB822jXAIDHCHkA8BghDwAeI+QBwGOEPAB4jJAHAI8R8gDgMUIeAMrsX3+yX4+/eCyUYxPyAFBm//K/+/XD3SdCOTYhDwBl5JxT35mEOprqQjk+IQ8AZTSSmFJiakbtjZFQjk/IA0AZnRiekCQqeQDw0b6+UUnSuvbGUI5PyANAGf3i+BmZSRs6GkI5PiEPAGX07P4BbeqKqylaG8rxCXkAKJOJ5LR6DwzopvXLQjsHIQ8AZfLD3Sc0kZzRrZs6QzsHIQ8AZeCc04PbDmhlc1Sv29Ae2nkIeQAog6df7tOz+wf0gVvWq7rKQjsPIQ8AJXZ6bFIff+RFXdbZqHtv7A71XIvqRt4A4LuJ5LTu+9p29Y9M6v73XKe6mupQz0clDwAlMjyR1O999Tk9++qAPvuuLdqypiX0c1LJA0AJbD8wqD95eIeODI7rb9+1RW/bsrIk5yXkASBEA6OT+sJTv9SD2w6oKx7V1++7SdevDW9dfC5CHgBCcHJ4Qg9uO6Cv/uRVjU5O6Z4buvWxOzaF9s3W+RDyALBApmectu3r1zd6D+n7Lx7T1IzTr1+xXH/25st1aWdTWcZEyANAEZLTM9p+YFA/2Hlc33vhmE6NJNRYV6P33HSJfvfmtVrbHs6FxwpFyAPABXDO6dX+MT2z95R+9HKfntnbr5HElCI1Vbr18k697eqVunVTp6K14S6NLBQhDwDnMD45rRePDGn7gUFtPzConx0c1MDopCRpVUtMv7Flpd6wsUO/cmlbyfvthSDkAUBn77W6+9iwdh8b1kvHzmj30SHtPzWqGZfaZ317g27d1KnrLmnVDeuWaX17g8zCuyTBQiDkASwpyekZHRwY076+Ue3rG9H+U6Pa1zeqvX0j6k9X6FKqSt+8Iq63XrVCV61u0bXdLWprDOcWfWEi5AF4xTmnofGkDg+O6/DgWPp5XIcGxrTv1KgODoxpOlOaS2priGh9R4Nu29ypTV1xXbEyrs1dcTXXL77Wy8Ug5AFUlMTUtE4OJ3RieEInhhM6ejoY5kdOj2skMRX4nYZItdYsq9fmFU2686ourW9v1PqOBq1vb/QmzOdDyANYFKZnnPpHEzo5nNDxoQmdODOhE0OpID8+PJEO9QkNjiXn/G5TXY1Wtca0Zlm9bt7QptWtsfSjXqtbY2qO1S763nlYCHkAoRmfnNapkYT6RyfVP5LQqZGETo1Mqn9kMv1+Iv3zpAZGE8rqokiSzKT2xjp1xaNa3RrTdZe0ank8quXxuvRzVCubY95X48Ug5AEUZGYm1eseHJvU4FhSpwPPkxoYTYX1qZFUcPePJDQ6OZ33WA2RarU31amtIaI1y+p1TXeL2hrq1BmvU2dTVF3NqSDvaKxTTTUXyy0GIQ8sQRPJ6VRYj54N68GxyZyfg89D40k5l/941VWmZQ0RtTVE1N5Yp0u669XWWKe2xojaG9LP6ddtDXWKRRbHF4WWAkIeqFATyWkNjyc1NJ7U8ETqeWg8qeHxqfRz7rap2ap7Ijkz73HrI9VqrY+opb5WrfURrWqJqbU+otb6WrXUR9TakH6uj2hZfUQtDbVqqqtZsj3vxS70kDezt0j6vKRqSV9xzn0m7HMClWBmxulMYupsGGcFciaohwLvnQ3r4YmkJqfmD2opFdbNsVrFo7VqjtVqVUtUV66Mnw3rnODOBHvYdypCaYUa8mZWLemLkn5N0mFJz5nZY8653WGeFyiVxNT02co5K4zPVtFTGhrLCeuJpIbGkjqTmJq3/SFJVSbFY6mAzoT1iuaY4rEaxbPCuzlWO7tfPFqj5litmqK1itTQy0b4lfwNkvY45/ZJkpk9JOkuSYQ8FoU51fREJqSngqE9MZVTTaf2PVfbQ5KitVWBanp5PKqNy5tmAzmeFdCz+9WntjXSAsECCDvkV0k6lPX6sKQbs3cws/sk3SdJ3d3h3rUc/nHOaTwZrKaD7Y+pvK2QzM8j56mmzaR4tDZVPaeD+tLOxtkwzhfWmf3isRpaHyi7sEM+XxkS+FfKObdV0lZJ6unpOce/bvDV9IzT8HhSp8dTKz2GJ3Ir66mcKjs5u8/wRFLJ6XP/tWmIVAfaGytbotoUbZoN5kyLI54T0PFYrRojNaqqoppG5Qo75A9LWpP1erWkoyGfE2WSnJ7R0HhSp8eSGhpPLb07PZYK76GxyXSIn32dWWM9PDF1zuNGqqvSgZyqplvqI+pua5g/nKNn+9RN0RrVss4aS1jYIf+cpMvMbJ2kI5LukXRvyOdEkTItkP6R1BdcBsYmNTBy9gsvqZBO6nRWkGdaH/OpMqk5lgro5litWhsiWtfeMPu6pT71aJ7T8qhVXU0VvWngIoUa8s65KTP7iKQnlFpC+YBzbleY58RcMzNuNqBnH+ngHsh5f3B0Uv2jk0rMszyvpspmw7ilPqKueFSXdzWpJRYJBHVLfUQtmfCORdQUpe0BlEPo6+Sdc49Lejzs8yw1zjmNJKbUdyaReowkzv6c87p/dDJwadVsjXU1WtYQUWtDRMvjUW3qiqutMbWGuq0hMrutLf0cj7LiA6gkfON1EUpOz+jkmYSOD43r2NCEjg9NZD2PzwZ4vuV7NVWm9sY6dTTVqbOpTleujKujqS79lfI6LatPBXcqvPniC+A7Qr4MRhJTOjQwpoMDYzo0kLoO9vGhCR0bntDxoXH1nZl7Nb5YbbVWtETVFY/quu5WdTTVnX00Rmd/bonV0hYBMIuQD4FzTv2jk9p7MnVrsYOZQE/fnWYg6xZjUqplsqI5deW9y5d3qKs5phXN0fQjpq7mKG0SABeFkC+Cc06HB8f1yokz2nNyRHv7RrQ3fa/I01k3NqipMq1qjal7Wb3e8pourWmtV/ey1GPNsqV9QwMA4SLkCzQ1PaM9fSPadWRYu44Oa9fRIe0+NqwzWWu82xvrtKGjQXdetUKXdjRqQ2ej1rc3aEVzlGtiAygLQn4eI4kp/fzgoHpfHdT2A4P6+cHB2RsgRGurtKkrrrdtWakrVsa1qatJGzoa1VIfKfOoASCIkE+bmXHaeXRIT7/cp6dfPqkdh05rxqW+xLOpK67fum61ru1u1WtWxbWuvVHVfLgJoAIs6ZCfmXHqPTCoR3cc0RO7juvUyKTMpNeuataH33Sprl+7TNd0t6gpyv0jAVSmJRnyJ89M6D9+elAPP3dIR4cmFKut1m2bO3Xb5k69/rIOtTfWlXuIALAgllTIHxoY0+ef+qUe3XFEyWmnWzZ26KN3bNLtm5eroW5J/aMAsEQsiWQbTUzpc//1ih7c9qqqzPTuGy/R+26+ROs7Gss9NAAIlfchv21fv/70G8/ryOlx/XbPGv3x7RvV1Rwt97AAoCS8DvmHnj2oT3xnp9a0xvTwB2/W9WuXlXtIAFBS3ob8vz3zqj752C7dsrFDX7z3GlbIAFiSvAz5p146oU99d5du37xcX3rPtdwZCMCS5V36DYxO6s+/+YKuWBHXP/zONQQ8gCXNu0r+C0/9UkPjSf37B25ULMK10gEsbV6Vuf0jCT303EH95jWrtKkrXu7hAEDZeRXy3/7ZEU0kZ/ShN6wv91AAYFHwKuSf2HVcV6yI69LOpnIPBQAWBW9CfmxyStsPDuq2zZ3lHgoALBrehPwvjp+Rc9JVq5rLPRQAWDS8CfndR4clSZtX8IErAGR4E/KvnDijproarW6NlXsoALBoeBPyx4cmtLIlxg2xASCLNyF/aiShjiZu9gEA2bwJ+b6RhNobuZE2AGTzJuTHJ2dUz92dACDAm5CXXLkHAACLjkchL/GRKwAEeRPyjkIeAObwJuQlidWTABDkTchTyAPAXP6EvHMyuvIAEOBNyEu0awAglzchT7sGAObyJuQlllACQC5vQp4llAAwV2ghb2afMrMjZrYj/bgzrHNJ6Q9eacoDQEDYF3v5O+fcZ0M+BwBgHv60a8o9AABYhMIO+Y+Y2Qtm9oCZtYZ8LpZQAkCOokLezJ40s515HndJ+pKkDZKulnRM0ufmOcZ9ZtZrZr19fX0XPxhKeQCYo6ievHPu9kL2M7N/lvS9eY6xVdJWSerp6bnoqHYS33gFgBxhrq5ZkfXybkk7wzrX2XOGfQYAqCxhrq75GzO7Wqki+1VJHwzxXHIslAeAOUILeefce8M69nwo5AEgiCWUAOAxb0JeoicPALm8CXla8gAwlz8hL65dAwC5vAl5iQ9eASCXNyFPuwYA5vIm5CVRygNADm9CnkIeAObyJuTluHYNAOTyJ+TFOnkAyOVNyDsaNgAwhzchL/G5KwDk8ibkWUIJAHP5E/KiJw8AubwJeYnVNQCQy5uQ56YhADCXNyEv0a4BgFzehDx1PADM5U3ISyyhBIBc3oQ8LXkAmMubkJdEUx4AcngV8kQ8AAR5EfIsnwSA/LwI+Qy6NQAQ5EXIU8gDQH5+hHz6mcsaAECQFyGfQbsGAIK8CHk+eAWA/LwI+QwKeQAI8iLkqeMBID8/Qj6d8vTkASDIi5AHAOTnRci7dMPGKOUBIMCLkAcA5OdFyLOCEgDy8yLkM+jWAECQVyEPAAjyIuRnl1DydSgACPAi5DNo1wBAUFEhb2bvNLNdZjZjZj052z5mZnvM7GUze3Nxwzw3x3deASCvmiJ/f6ekt0v6cvabZnaFpHskXSlppaQnzWyjc266yPOdE4U8AAQVVck7515yzr2cZ9Ndkh5yziWcc/sl7ZF0QzHnOvc4wjoyAFS2sHryqyQdynp9OP3eHGZ2n5n1mllvX1/fRZ1s9qYhlPIAEHDedo2ZPSmpK8+mTzjnHp3v1/K8l7feds5tlbRVknp6eoqqyVldAwBB5w1559ztF3Hcw5LWZL1eLenoRRynINw0BADyC6td85ike8yszszWSbpM0rMhnWsW7RoACCp2CeXdZnZY0s2Svm9mT0iSc26XpIcl7Zb0A0kfDnNlDXU8AORX1BJK59wjkh6ZZ9unJX26mOMDAIrjxTdeackDQH5ehLxmb/9HUx4AsvkR8mlEPAAEeRHyXLsGAPLzIuQz6NYAQJAXIc8HrwCQnx8hn36mkAeAIC9CPoPVNQAQ5EXIc+0aAMjPi5DPoJAHgCAvQp46HgDy8yPkM994Le8wAGDR8SLkZ9GvAYAAL0Keb7wCQH5ehHwGdTwABPkR8hTyAJCXHyGfRkseAIK8CHkKeQDIz4+Qn11CSSkPANm8CPkM2jUAEORFyLOEEgDy8yLkMyjkASDIi5DnIpQAkJ8fIZ9+picPAEFehHwGq2sAIMiLkOemIQCQnxchP4tCHgACvAh5CnkAyM+LkM+gkAeAIL9CnuU1ABDgRcjTrgGA/LwI+QzqeAAI8iLkuXYNAOTnRchn0JIHgCAvQp6ePADk50fIp5+p5AEgyIuQz+DaNQAQ5EXIc+0aAMjPi5DPoF0DAEFFhbyZvdPMdpnZjJn1ZL2/1szGzWxH+nF/8UOdH3U8AORXU+Tv75T0dklfzrNtr3Pu6iKPXxC6NQCQX1Eh75x7SVo814xZLOMAgMUizJ78OjP7uZn9yMxeP99OZnafmfWaWW9fX99FnopSHgDyOW8lb2ZPSurKs+kTzrlH5/m1Y5K6nXP9ZnadpO+Y2ZXOueHcHZ1zWyVtlaSenp6i0po6HgCCzhvyzrnbL/SgzrmEpET65+1mtlfSRkm9FzzCgs4XxlEBoPKF0q4xsw4zq07/vF7SZZL2hXEuiW+8AsB8il1CebeZHZZ0s6Tvm9kT6U23SHrBzJ6X9E1JH3LODRQ31ALGQ8MGAAKKXV3ziKRH8rz/LUnfKubYFzaOUp0JACoL33gFAI95EfLcNAQA8vMi5DMo5AEgyIuQpycPAPl5FfL05AEgyIuQP4uUB4BsXoQ8H7wCQH5ehHwG7RoACPIi5PngFQDy8yLkMyjkASDIr5CnXwMAAV6EPO0aAMjPi5DPoI4HgCAvQp4llACQnx8hzzdeASAvL0I+g5AHgCAvQr45Vqu3XrVCnU3Rcg8FABaVou4MtVisbW/QF999bbmHAQCLjheVPAAgP0IeADxGyAOAxwh5APAYIQ8AHiPkAcBjhDwAeIyQBwCPmVtE1+k1sz5JB4o4RLukUws0nEqw1OYrMeelgjlfmEuccx35NiyqkC+WmfU653rKPY5SWWrzlZjzUsGcFw7tGgDwGCEPAB7zLeS3lnsAJbbU5isx56WCOS8Qr3ryAIAg3yp5AEAWQh4APFZxIW9mbzGzl81sj5n9RZ7tZmZfSG9/wcwq/m4iBcz53em5vmBmz5jZlnKMcyGdb85Z+11vZtNm9o5Sji8MhczZzN5oZjvMbJeZ/ajUY1xoBfzdbjaz75rZ8+k5v78c41woZvaAmZ00s53zbF/4/HLOVcxDUrWkvZLWS4pIel7SFTn73CnpPyWZpJsk/bTc4y7BnF8nqTX98x1LYc5Z+/23pMclvaPc4y7Bn3OLpN2SutOvO8s97hLM+eOS/jr9c4ekAUmRco+9iDnfIulaSTvn2b7g+VVplfwNkvY45/Y55yYlPSTprpx97pL0NZeyTVKLma0o9UAX0Hnn7Jx7xjk3mH65TdLqEo9xoRXy5yxJfyjpW5JOlnJwISlkzvdK+rZz7qAkOecqfd6FzNlJajIzk9SoVMhPlXaYC8c592Ol5jCfBc+vSgv5VZIOZb0+nH7vQvepJBc6n99XqhKoZOeds5mtknS3pPtLOK4wFfLnvFFSq5k9bWbbzex9JRtdOAqZ8z9K2izpqKQXJf2Rc26mNMMriwXPr0q7kbfleS93DWgh+1SSgudjZm9SKuR/NdQRha+QOf+9pI8656ZTRV7FK2TONZKuk3SbpJik/zOzbc65V8IeXEgKmfObJe2QdKukDZJ+aGb/45wbDnls5bLg+VVpIX9Y0pqs16uV+i/8he5TSQqaj5m9VtJXJN3hnOsv0djCUsiceyQ9lA74dkl3mtmUc+47JRnhwiv07/Yp59yopFEz+7GkLZIqNeQLmfP7JX3GpRrWe8xsv6RNkp4tzRBLbsHzq9LaNc9JuszM1plZRNI9kh7L2ecxSe9Lf0p9k6Qh59yxUg90AZ13zmbWLenbkt5bwVVdtvPO2Tm3zjm31jm3VtI3Jf1BBQe8VNjf7Uclvd7MasysXtKNkl4q8TgXUiFzPqjU/7nIzJZLulzSvpKOsrQWPL8qqpJ3zk2Z2UckPaHUJ/MPOOd2mdmH0tvvV2qlxZ2S9kgaU6oSqFgFzvkvJbVJ+qd0ZTvlKvgKfgXO2SuFzNk595KZ/UDSC5JmJH3FOZd3KV4lKPDP+a8kfdXMXlSqlfFR51zFXoLYzL4u6Y2S2s3ssKRPSqqVwssvLmsAAB6rtHYNAOACEPIA4DFCHgA8RsgDgMcIeQDwGCEPAB4j5AHAY/8PBm24WC9XRosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_tanh_space(torch.Tensor(np.arange(-1,1,.001)).double(), [0., 1.])\n",
    "pd.Series(to_tanh_space(torch.Tensor(np.arange(-1,1,.001)).double(), [0., 1.]).tolist(), \n",
    "          index=np.arange(-1,1,.001)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "comic-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor(np.random.randint(0,2, (3,4)))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "useful-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[inf, inf, -inf, -inf],\n",
       "        [-inf, -inf, inf, inf],\n",
       "        [-inf, inf, -inf, inf]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tanh_space(inputs, [0., 1.])#, min=-1e4, max=1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "statewide-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(inputs + from_tanh_space(pert_tanh*1000, [0., 1.]), max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "velvet-worth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9125,  1.7148, -0.6042,  0.3287],\n",
       "        [ 0.8110,  0.7492, -0.4228, -0.1139],\n",
       "        [-0.0307,  0.3254,  0.4284,  1.6197]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_tanh = torch.zeros((3,4))  # type: torch.FloatTensor\n",
    "nn.init.normal_(pert_tanh, mean=0, std=1)\n",
    "pert_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "impaired-comment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_tanh_space(pert_tanh*1e4, [0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-bangkok",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "palestinian-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(from_tanh_space(\n",
    "    (to_tanh_space(torch.Tensor(np.arange(-1,1,.001)).double(), [-1., 1.])*1000), [-1., 1]).tolist(),\n",
    "    index=to_tanh_space(torch.Tensor(np.arange(-1,1,.001)).double(), [-1., 1.]).tolist()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "compliant-server",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(from_tanh_space(torch.Tensor(np.arange(-1000, 1000, 1)), box=[0,1]).tolist(),\n",
    "    index=np.arange(-1000, 1000, 1)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automated-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.9990], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_tanh_space(to_tanh_space(torch.Tensor([0,.999]).double(), [-1., 1.]), [-1., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # Training settings\n",
    "#     parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "#     parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "#                         help='input batch size for training (default: 64)')\n",
    "#     parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "#                         help='input batch size for testing (default: 1000)')\n",
    "#     parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "#                         help='number of epochs to train (default: 14)')\n",
    "#     parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "#                         help='learning rate (default: 1.0)')\n",
    "#     parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "#                         help='Learning rate step gamma (default: 0.7)')\n",
    "#     parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "#                         help='disables CUDA training')\n",
    "#     parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "#                         help='quickly check a single pass')\n",
    "#     parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "#                         help='random seed (default: 1)')\n",
    "#     parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "#                         help='how many batches to wait before logging training status')\n",
    "#     parser.add_argument('--save-model', action='store_true', default=False,\n",
    "#                         help='For Saving the current Model')\n",
    "#     args = parser.parse_args()\n",
    "#     use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "#     torch.manual_seed(args.seed)\n",
    "\n",
    "#     device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "#     train_kwargs = {'batch_size': args.batch_size}\n",
    "#     test_kwargs = {'batch_size': args.test_batch_size}\n",
    "#     if use_cuda:\n",
    "#         cuda_kwargs = {'num_workers': 1,\n",
    "#                        'pin_memory': True,\n",
    "#                        'shuffle': True}\n",
    "#         train_kwargs.update(cuda_kwargs)\n",
    "#         test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "#     # load data (will need to be adapted as well)\n",
    "#     # 1) load A_test\n",
    "#     # 2) load labels\n",
    "#     # 3) Perform train-test-split\n",
    "# #     transform=transforms.Compose([\n",
    "# #         transforms.ToTensor(),\n",
    "# #         transforms.Normalize((0.1307,), (0.3081,))\n",
    "# #         ])\n",
    "# #     dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "# #                        transform=transform)\n",
    "# #     dataset2 = datasets.MNIST('../data', train=False,\n",
    "# #                        transform=transform)\n",
    "#     dataset = HindroidDataset(\n",
    "#         'data/out/all-apps/hindroid-train-half/A_test.npz', \n",
    "#         'data/out/all-apps/hindroid-train-half/predictions.csv',\n",
    "#         'AAT'\n",
    "#     )\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset,**train_kwargs)\n",
    "#     test_loader = torch.utils.data.DataLoader(dataset, **test_kwargs)\n",
    "\n",
    "#     model = HindroidSubstitute().to(device)\n",
    "#     optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "#     scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "#     for epoch in range(1, args.epochs + 1):\n",
    "#         train(args, model, device, train_loader, optimizer, epoch)\n",
    "#         test(model, device, test_loader)\n",
    "#         scheduler.step()\n",
    "\n",
    "#     if args.save_model:\n",
    "#         torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
